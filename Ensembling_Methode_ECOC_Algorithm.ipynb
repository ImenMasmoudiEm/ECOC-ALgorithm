{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfKK7tUOSGiY1oWKSDy+JQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImenMasmoudiEm/ECOC-ALgorithm/blob/main/Ensembling_Methode_ECOC_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mIp4l4Y0_79",
        "outputId": "3665eb7a-3550-407b-95d5-870d48d7e967"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H85ybNJ_yLfe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import os \n",
        "os.chdir('/content/drive/MyDrive/All/Projects/Ing Internship/Data')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data\n"
      ],
      "metadata": {
        "id": "klpWdEse1MPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tunnel=pd.read_excel(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/final-dataset.xlsx\")"
      ],
      "metadata": {
        "id": "kjdUVLTX1Oog"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the Tunnal Dataset\n",
        "Tunnel['classe']=Tunnel['classe'].replace(\"hate\", int(2))\n",
        "Tunnel['classe']=Tunnel['classe'].replace(\"normal\", int(0)) \n",
        "Tunnel['classe']=Tunnel['classe'].replace(\"abusive\", int(1))\n",
        "\n",
        "\n",
        "TunnelS = Tunnel['commentaire']\n",
        "TunnelL = Tunnel['classe']\n",
        "\n",
        "TunnalL = [int(i) for i in TunnelL]"
      ],
      "metadata": {
        "id": "Cn6s5VUy1pCa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_size=int(len(TunnelS)*0.9) \n",
        "\n",
        "training_sentences = TunnelS[0:training_size]\n",
        "TunnelS = TunnelS[training_size:]\n",
        "TunnelL = TunnelL[training_size:]\n",
        "\n",
        "tokenizer = Tokenizer(num_words=3000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#For Tunnel Dataset\n",
        "TunnelS = tokenizer.texts_to_sequences(TunnelS)\n",
        "TunnelS207 = pad_sequences(TunnelS, maxlen=207, padding='post', truncating='post')\n",
        "TunnelS388 = pad_sequences(TunnelS, maxlen=388, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "JWuvFt7Y2g2L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TunnelS207[1]"
      ],
      "metadata": {
        "id": "a-WEMNySTzNK",
        "outputId": "b402a6fe-a659-4503-8386-5635fe6d9dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 307,   61,  307, 2079,  169,   14,   43, 2790, 1650, 2079, 2807,\n",
              "        653,    1,    1,    3,  243,    1,    1,    1,    3,  212,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the models\n",
        "M1B09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Balanced 09/Model1Balanced09.h5\")\n",
        "M1U09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Unbalanced 09/Model1Unbalanced09.h5\")\n",
        "M2B09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Balanced 09/Model2Balanced09.h5\")\n",
        "M2U09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Unbalanced 09/Model2Unbalanced09.h5\")\n",
        "M3B09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Balanced 09/Model3Balanced09.h5\")\n",
        "M3U09=tf.keras.models.load_model(\"/content/drive/MyDrive/All/Projects/Ing Internship/Data/Unbalanced 09/Model3Unbalanced09.h5\")"
      ],
      "metadata": {
        "id": "W3gFxkmB5pou"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions for Tunnel\n",
        "TunnelP11=M1B09.predict(TunnelS207)\n",
        "TunnelP21=M1U09.predict(TunnelS388)\n",
        "TunnelP31=M2B09.predict(TunnelS207)\n",
        "TunnelP41=M2U09.predict(TunnelS388)\n",
        "TunnelP51=M3B09.predict(TunnelS207)\n",
        "TunnelP61=M3U09.predict(TunnelS388)"
      ],
      "metadata": {
        "id": "1hU12_YP3aUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f14a2a-5e6f-42a7-bee6-b3fcab2d8359"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 10s 100ms/step\n",
            "72/72 [==============================] - 14s 163ms/step\n",
            "72/72 [==============================] - 9s 91ms/step\n",
            "72/72 [==============================] - 14s 162ms/step\n",
            "72/72 [==============================] - 9s 91ms/step\n",
            "72/72 [==============================] - 14s 160ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First approach: Argmax and then look for the max\n",
        "\n",
        "def fcount(c,L):\n",
        "  r=0\n",
        "  for i in L:\n",
        "    if i==c:\n",
        "      r+=1\n",
        "  return r\n",
        "\n",
        "def MaxV(L1,L2,L3,L4,L5,L6):\n",
        "  L=np.zeros(len(L1))\n",
        "  for i in range(len(L1)):\n",
        "    if (fcount(2,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])>fcount(0,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])) and (fcount(2,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])>fcount(1,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])):\n",
        "      L[i]=2\n",
        "    elif (fcount(1,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])>fcount(0,[L1[i],L2[i],L3[i],L4[i],L5[i],L6[i]])):\n",
        "      L[i]=1\n",
        "    else:\n",
        "      L[i]=0\n",
        "  return L\n",
        "\n",
        "#For the Tunnel Dataset\n",
        "TunnelP1=np.argmax(TunnelP11, axis=1).astype(int)\n",
        "TunnelP2=np.argmax(TunnelP21, axis=1).astype(int)\n",
        "TunnelP3=np.argmax(TunnelP31, axis=1).astype(int)\n",
        "TunnelP4=np.argmax(TunnelP41, axis=1).astype(int)\n",
        "TunnelP5=np.argmax(TunnelP51, axis=1).astype(int)\n",
        "TunnelP6=np.argmax(TunnelP61, axis=1).astype(int)\n",
        "\n",
        "TunnelP=MaxV(TunnelP1,TunnelP2,TunnelP3,TunnelP4,TunnelP5,TunnelP6)\n",
        "\n",
        "cm = confusion_matrix(TunnelL, TunnelP)\n",
        "print('Testing on the Tunnel Dataset')\n",
        "print(cm)\n",
        "print(classification_report(TunnelL, TunnelP, labels=[0,1,2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81uhYBIeDUo",
        "outputId": "887ab560-c6c0-49a0-aa74-14f2845069aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on the Tunnel Dataset\n",
            "[[1256    3    6]\n",
            " [ 135  268   11]\n",
            " [ 187  100  338]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88      1265\n",
            "           1       0.72      0.65      0.68       414\n",
            "           2       0.95      0.54      0.69       625\n",
            "\n",
            "    accuracy                           0.81      2304\n",
            "   macro avg       0.82      0.73      0.75      2304\n",
            "weighted avg       0.83      0.81      0.79      2304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second approach: We add the predictions and then we apply Argmax\n",
        "\n",
        "#Testing on the Tunnel Dataset\n",
        "TunnelPF=np.asarray(TunnelP11)+np.asarray(TunnelP21)+np.asarray(TunnelP31)+np.asarray(TunnelP41)+np.asarray(TunnelP51)+np.asarray(TunnelP61)\n",
        "TunnelPF=np.argmax(TunnelPF, axis=1).astype(int)\n",
        "\n",
        "cm = confusion_matrix(TunnelL, TunnelPF)\n",
        "print('Testing on the Tunnel Dataset')\n",
        "print(cm)\n",
        "print(classification_report(TunnelL, TunnelPF, labels=[0,1,2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_olf9YI-zL4",
        "outputId": "b7438475-02c8-40d7-8da6-d8a05455cd5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on the Tunnel Dataset\n",
            "[[1157   41   67]\n",
            " [  63  292   59]\n",
            " [  90   50  485]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.90      1265\n",
            "           1       0.76      0.71      0.73       414\n",
            "           2       0.79      0.78      0.78       625\n",
            "\n",
            "    accuracy                           0.84      2304\n",
            "   macro avg       0.81      0.80      0.81      2304\n",
            "weighted avg       0.84      0.84      0.84      2304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Third approach: We use a Neural Network Model\n",
        "\n",
        "#The Tunnel Dataset\n",
        "TunnelL=np.asarray(TunnelL)\n",
        "TunnelP=np.asarray(TunnelP)\n",
        "XTunnel=[]\n",
        "for i in range(len(TunnelL)):\n",
        "  #print([TunnelP1[i],TunnelP2[i],TunnelP3[i],TunnelP4[i],TunnelP5[i],TunnelP6[i]],\" the true value is: \", TunnelL[i], \"P= \", TunnelP[i])\n",
        "  XTunnel.append([TunnelP1[i],TunnelP2[i],TunnelP3[i],TunnelP4[i],TunnelP5[i],TunnelP6[i]])"
      ],
      "metadata": {
        "id": "cOIfAkZzjXIQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TunnelL=np.asarray(TunnelL)\n",
        "\n",
        "XTunnel=np.asarray(XTunnel)"
      ],
      "metadata": {
        "id": "hwlNLFSVMwW0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEModelTunnel = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(6,)),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(24, activation='selu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "FEModelTunnel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EFktnE7km3P",
        "outputId": "2d5eef23-aaa6-4aaa-84c9-ff5498e9d538"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 6)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               896       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                3096      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 75        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,067\n",
            "Trainable params: 4,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEModelTunnel.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "history = FEModelTunnel.fit(XTunnel, TunnelL, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adwrCC1Ok853",
        "outputId": "c40784e2-acf4-45d4-e3e4-d6cc04ad8e15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.7883 - accuracy: 0.6753\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8802\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.9501\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.9588\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.9588\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.9588\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.9588\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.9588\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9588\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.9588\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9588\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9588\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9588\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9588\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9588\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9588\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9588\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9588\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9588\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9588\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9588\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9588\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9588\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9588\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9588\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9588\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9588\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9588\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9588\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9588\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9588\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9588\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9588\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9588\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9588\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9588\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9588\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9588\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9588\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9588\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9588\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9588\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9588\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9588\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9588\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9588\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9588\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9588\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9588\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TunnelFP=FEModelTunnel.predict(XTunnel)"
      ],
      "metadata": {
        "id": "MRnFhH1YOPz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697b6bbc-6fb4-464d-e2db-168a8c35f858"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Third approach on the Tunnel Dataset\n",
        "TunnelFP=np.argmax(TunnelFP, axis=1).astype(int)\n",
        "cm = confusion_matrix(TunnelL, TunnelFP)\n",
        "print('Testing on the Tunnel Dataset')\n",
        "print(cm)\n",
        "print(classification_report(TunnelL, TunnelFP, labels=[0,1,2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sp_G1OwOej9",
        "outputId": "916493f2-03c4-41dc-f809-c9d27f632796"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on the Tunnel Dataset\n",
            "[[1254    2    9]\n",
            " [  15  375   24]\n",
            " [  33   12  580]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      1265\n",
            "           1       0.96      0.91      0.93       414\n",
            "           2       0.95      0.93      0.94       625\n",
            "\n",
            "    accuracy                           0.96      2304\n",
            "   macro avg       0.96      0.94      0.95      2304\n",
            "weighted avg       0.96      0.96      0.96      2304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YxXQ409tiq5i"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}